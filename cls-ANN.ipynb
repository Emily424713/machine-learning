{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN MODEL FOR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow\n",
    "# ! pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"TrainDataset2023.xls\"\n",
    "# # file_path = \"TrainDataset2023.xls\"\n",
    "\n",
    "# df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded dataset and pickle\n",
    "file_path = \"TrainDataset2023.csv\"\n",
    "df=pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded dataset and pickle\n",
    "# file_path = \"TrainDataset2023.csv\"\n",
    "# df=pd.read_csv(file_path)\n",
    "df.head()\n",
    "target_lable=\"pCR (outcome)\"\n",
    "# model_path=\"model/cls_ann\"\n",
    "# pickle.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# # # 创建一个包含'ID'列的示例DataFrame，以及其他可能需要填充的列\n",
    "# # data = {'ID': [1, 2, 3, 4],\n",
    "# #         'A': [1, 2, np.nan, 4],\n",
    "# #         'B': [4, 5, 6, 7],\n",
    "# #         'C': [7, np.nan, 9, 10]}\n",
    "\n",
    "# # df = pd.DataFrame(data)\n",
    "\n",
    "# # 将'ID'列保存到一个单独的Series中\n",
    "# id_column = df['ID']\n",
    "\n",
    "# # 从DataFrame中移除'ID'列，以便进行填充\n",
    "# df.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "# # 初始化KNNImputer，指定n_neighbors\n",
    "# knn_imputer = KNNImputer(missing_values='NaN',n_neighbors=1)\n",
    "\n",
    "# # 执行KNN填充\n",
    "# imputed_data = knn_imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 使用isna()方法检查每一列是否包含NaN值\n",
    "nan_columns = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# 输出包含NaN值的列\n",
    "print(\"包含NaN值的列:\", nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# # 创建一个示例数据集，包含NaN值\n",
    "# data = np.array([[1, 2, np.nan],\n",
    "#                  [4, np.nan, 6],\n",
    "#                  [7, 8, 9],\n",
    "#                  [np.nan, 11, 12]])\n",
    "\n",
    "# 初始化KNNImputer，指定n_neighbors\n",
    "knn_imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "# 使用KNN imputer填充NaN值\n",
    "imputed_data = knn_imputer.fit_transform(df)\n",
    "\n",
    "# 输出填充后的数据\n",
    "print(\"Imputed Data:\")\n",
    "print(imputed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 使用isna()方法检查每一列是否包含NaN值\n",
    "nan_columns = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# 输出包含NaN值的列\n",
    "print(\"包含NaN值的列:\", nan_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 创建一个包含字符串'nan'的示例DataFrame\n",
    "data = {'A': [1, 'nan', 3, 4],\n",
    "        'B': ['nan', 6, 'nan', 8]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 将字符串'nan'转换为np.nan\n",
    "df = df.apply(lambda x: np.where(x == 'nan', np.nan, x))\n",
    "\n",
    "# 输出转换后的DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 将字符串'nan'转换为np.nan\n",
    "# df = df.apply(lambda x: np.where(x == '999', np.nan, x))\n",
    "\n",
    "# # 输出转换后的DataFrame\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化KNNImputer，指定n_neighbors\n",
    "knn_imputer = KNNImputer(missing_values='NaN',n_neighbors=1)\n",
    "\n",
    "# 执行KNN填充\n",
    "imputed_data = knn_imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用isna()方法检查每一列是否包含NaN值\n",
    "nan_columns = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# 输出包含NaN值的列\n",
    "print(\"包含NaN值的列:\", nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将填充后的数据与'ID'列重新组合\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=df.columns)\n",
    "imputed_df['ID'] = id_column\n",
    "\n",
    "# 输出填充后的DataFrame\n",
    "print(\"Imputed DataFrame:\")\n",
    "print(imputed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# # 使用isna()方法检查每一列是否包含NaN值\n",
    "# nan_columns = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# # 输出包含NaN值的列\n",
    "# print(\"包含NaN值的列:\", nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# # # Create a sample dataset with missing values\n",
    "# # data = np.array([[1, 2, np.nan],\n",
    "# #                  [4, 5, 6],\n",
    "# #                  [7, np.nan, 9],\n",
    "# #                  [10, 11, 12]])\n",
    "\n",
    "# # Initialize the KNNImputer with the desired number of neighbors (k)\n",
    "# knn_imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "# # Perform KNN imputation\n",
    "# imputed_data = knn_imputer.fit_transform(df)\n",
    "\n",
    "# # The missing values have been filled in using KNN imputation\n",
    "# print(\"Imputed Data:\")\n",
    "# print(imputed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# imputer = SimpleImputer(missing_values='NaN',strategy='mean')\n",
    "# df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "# df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop(columns=[target_lable, 'RelapseFreeSurvival (outcome)'])\n",
    "# # X = df.drop(columns=[target_lable, 'RelapseFreeSurvival (outcome)',\"ID\"])\n",
    "# # X\n",
    "\n",
    "# Assign features to X\n",
    "X = df.drop(columns=['ID',target_lable, 'RelapseFreeSurvival (outcome)'], axis=1)\n",
    "# X = df.drop(columns=[target_lable, 'RelapseFreeSurvival (outcome)'], axis=1,inplace=True)\n",
    "# X=None\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data imputation \n",
    "# Use regression model to do data imputation\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "impute_it = IterativeImputer()\n",
    "impute_it.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data imputation\n",
    "# Use KNN model to do data imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "impute_knn = KNNImputer(n_neighbors=2)\n",
    "impute_knn.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the outcome\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[target_lable] = le.fit_transform(df[target_lable])\n",
    "df.head()\n",
    "\n",
    "# assign numerical label to y\n",
    "y = df[target_lable]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the features using zero mean normalisation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "Xs_df = pd.DataFrame(Xs, columns=X.columns)\n",
    "Xs_df['ID'] = df[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # Data Preprocessing\n",
    "# def preprocess_data(df):\n",
    "#     # Imputing missing values\n",
    "#     imputer = SimpleImputer(missing_values='NaN',strategy='mean')\n",
    "   \n",
    "#     df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "#     # Separating features and target label\n",
    "#     X = df_imputed.drop('pCR (outcome)', axis=1)\n",
    "#     y = df_imputed['pCR (outcome)']\n",
    "\n",
    "#     # Normalizing the data\n",
    "#     scaler = StandardScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#     return train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 使用isna()方法检查每一列是否包含NaN值\n",
    "nan_columns = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# 输出包含NaN值的列\n",
    "print(\"包含NaN值的列:\", nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs_df, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# # set ANN model\n",
    "# model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=(X_train.shape[1] -1,)),\n",
    "#     layers.Dense(32, activation='relu'),\n",
    "#     layers.Dense(1)  # Output layer for regression, no activation function\n",
    "# ])\n",
    "# then i compiled the model\n",
    "# model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "keras.fit(X_train.loc[:, X_train.columns != 'ID'], y_train, epochs=50, batch_size=32, validation_split=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluated the model on the test set\n",
    "mae = model.evaluate(X_test.loc[:, X_test.columns != 'ID']\n",
    ", y_test)\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "\n",
    "# predictions\n",
    "y_pred = model.predict(X_test.loc[:, X_test.columns != 'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = { 'ID': X_test[\"ID\"], 'Prediction': y_pred.reshape((y_pred.shape[0],))}\n",
    "final_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
