{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN MODEL FOR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pandas in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/violetbenin/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded dataset and pickle\n",
    "file_path = \"TrainDataset2023.csv\"\n",
    "df=pd.read_csv(file_path)\n",
    "df.head()\n",
    "target_lable=\"pCR (outcome)\"\n",
    "# model_path=\"model/cls_ann\"\n",
    "# pickle.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('ID', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df[target_lable]\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target_lable, 'RelapseFreeSurvival (outcome)'])\n",
    "# X = df.drop(columns=[target_lable, 'RelapseFreeSurvival (outcome)',\"ID\"])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df[target_lable]\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the outcome\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[target_lable] = le.fit_transform(df[target_lable])\n",
    "df.head()\n",
    "# assign numerical label to y\n",
    "y = df[target_lable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign features to X\n",
    "X = df.drop(columns=[target_lable, 'RelapseFreeSurvival (outcome)'], axis=1)\n",
    "# X = df.drop(columns=[target_lable, 'RelapseFreeSurvival (outcome)'], axis=1,inplace=True)\n",
    "# X=None\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the features using zero mean normalisation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# • Perform PCA and retain the first 3 principal components\n",
    "from sklearn.decomposition import PCA\n",
    "feature_names = list(X.columns)\n",
    "pca = PCA(n_components=10)\n",
    "Xs_pca = pca.fit_transform(Xs)\n",
    "Xs_pca=Xs_pca[:,0:3] #retain the first 3 PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# • Build a Multiple Layer Perceptron Neural Network. Try to build different MLP structures.\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(10, input_dim=3,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# • Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\",\n",
    "metrics=[\"accuracy\"])\n",
    "# save the initial weight for initilise new models in cross validation\n",
    "model.save_weights('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# • A quick test of the model using 80% / 20% training and testing split.\n",
    "# Then we split the data to train and test 80%/20%\n",
    "Xs_train, Xs_test, y_train, y_test = train_test_split(Xs_pca, y, test_size=0.2,\n",
    "random_state=1, stratify=y)\n",
    "# Now we can start the training\n",
    "# Tensorflow/Keras uses np array, so need to convert the data format\n",
    "#make sure the weights are initialised\n",
    "model.load_weights('model.h5')\n",
    "# Model learning\n",
    "history= model.fit(np.array(Xs_train), np.array(y_train), epochs=50,\n",
    "validation_data=(np.array(Xs_test), np.array(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the training process, loss and accuracy\n",
    "import pandas as pd\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a K-fold cross validation. Observe the training process of each fold.\n",
    "# We will also visualise the training process using Tensorboard later. Search\n",
    "# for the meaning and usage of each function that you don’t know.\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "# root file for logging the learning process and can be visualised later in\n",
    "# tensorboard\n",
    "root_logdir = os.path.join(os.curdir, \"logs\")\n",
    "def get_run_logdir():\n",
    "import time\n",
    "run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir()\n",
    "kf = KFold(n_splits=5)\n",
    "k=1;\n",
    "for train_index, test_index in kf.split(Xs_pca):\n",
    "print(\"fold\",k)\n",
    "# initialise the weight for each fold\n",
    "model.load_weights('model.h5')\n",
    "# Split the data\n",
    "X_train, X_test = Xs_pca[train_index], Xs_pca[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "# tensorboard for visualising the training process later\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "# training and validation\n",
    "model.fit(np.array(X_train), np.array(y_train), epochs=10,\n",
    "validation_data=(np.array(X_test),\n",
    "np.array(y_test)),callbacks=[tensorboard_cb])\n",
    "#save the model of each fold\n",
    "model.save(os.path.join('fold_{}_model.hdf5'.format(k)))\n",
    "# evaluate the accuracy of each fold\n",
    "scores = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now use the model to perform prediction of new data.\n",
    "#load one model to do prediction\n",
    "model.load_weights('fold_5_model.hdf5')\n",
    "# You can use “predict” to predict output in the range of [0 1]\n",
    "y_pred=model.predict(np.array(X_test))\n",
    "# Or use model.evaluate to get the accuracy if the true labels are known\n",
    "# Here we use the test data of the last fold as an example,\n",
    "# in practice this should be an independent test set\n",
    "loss, acc = model.evaluate(np.array(X_test), np.array(y_test), verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
